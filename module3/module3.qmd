---
title: "SESSION 3 - Introduction to Trimming, Assembly and QC"
---

### Module Leads: Julio Diaz Caballero, Natacha Couto, Georgina Lewis-Woodhouse, Emmanuelle Kumaran, Nabil Fareed-Alikhan, Sophia David, Monica Abrudan

#### ***based on the exercise developed by Silvia Argimon***

# Table of contents

-   [Introduction](#introduction)
-   [Objectives](#learning-outcomes)
-   [Trim, assemble and QC with GHRU Nextflow pipeline](#obtain-high-quality-assemblies)

# Introduction {#introduction}

*Note: This exercise is a work of fiction. Any resemblance to a real life situation is purely coincidental.*

In December 2020, three cases of primary bloodstream infections sustained by ertapenem-resistant *Klebsiella pneumoniae* were observed over a two-week period in the neonatal intensive care unit (NICU) at the University College Hospital in Ibadan, Oyo State. This NICU consists of a 15-bed tertiary level ward. Since the detection of these infections, faecal screening of all admitted neonates was performed. Additionally, ten samples from the environment were collected. The epidemiological and demographic data is summarised in the file [epi_data.csv](data/epi_data.csv).

<img src="img/unit.png" width="70%" height="70%"/><br/>
Plan of the NICU. Locations of sample collection is indicated with light blue circles.
<br/><br/>

The reference lab sent you the culture results from the faecal, bloodstream, and environmental sampling in an Excel file called ([`lab_results.xlsx`](data/lab_results.xlsx)). Faecal screening of the admitted neonates, revealed that **five other neonates** were carriers of *K. pneumoniae*. Also, the lab reported that **2 out of 10** environmental samples were positive for *K. pneumoniae*. **This immediately prompted the closure of 1 room.**

One colony from each confirmed case and from each of the two positive environmental samples were sent to the GHRU-Ibadan unit for sequencing. 

It is now up to you to investigate the possibility of an outbreak of *K. pneumoniae* in the neonatal unit using the raw sequencing data, the GHRU assembly pipeline, Pathogenwatch, data-flo and Microreact, free web applications developed by the Centre for Genomic Pathogen Surveillance for data analyses, integration and visualisation.

# Objectives {#learning-outcomes}

At the end of this session the participants will be able to:

1.  Trim, assemble and QC with GHRU Nextflow pipeline
2.  Obtain high quality assemblies for downstream analysis
3.  Identify and discard low quality genomes
4.  Determine the probable cause of issues during sequencing and assembly

# Trim, assemble and QC with GHRU Nextflow pipeline {#obtain-high-quality-assemblies}

The pipeline we will be using is available here `https://gitlab.com/cgps/ghru/pipelines/dsl2/pipelines/assembly`

## Hardware

For this exercise you will use our pre configured bioinformatics servers. Connecting to our bioinformatics servers ensure the computational resources required for the assembly process are available. If you wish to run through this module on another
platform, you will need to install the required software and download the sample data yourself. 

To connect to our bioinformatics servers, follow the instructions below. Replace `user` with your username and `ghru-assembly` with the name of the server you want to connect to. You will need to enter your password when prompted. Your password will be provided to you by one of the instructors:

```bash
# Connect to the server
ssh user@159.65.95.44
```

## Data

You will find 11 sets of paired-end Illumina reads in the `/data/`. Thus, this directory will contain 22 fastq files (two per genome). You can check the data is actually there:

```bash
# Check the contents of the /data/ directory
ls /data/
```

The /data directory will serve as the input directory for the GHRU assembly pipeline. You can practice fetching the data from a remote location such as Figshare, ENA or SRA following the instructions in the [fetching data](#fetching-data)  bonus section.

If you wish to download a new copy of the sample data, there are instructions in the [Fetching data](#fetching-data) bonus sections. 

## Software

The assembly process pipeline will process each pair of Illumina short-read fastq files and assemble them using the [SPAdes assembler](https://github.com/ablab/spades). Along the assembly process, the workflow will perform quality control checks and filters. Some of the most important steps are:

1.  Trimming of Illumina adapters and low quality bases using [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic)
2.  Quality control of the reads using [FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/)
3.  Assembly of the reads using SPAdes
4.  Quality control of the assemblies using [QUAST](http://quast.sourceforge.net/)


Nextflow is already installed in our bioinformatics servers, and the assembly pipeline can be found in `/opt/ghru-assembly`. Let's check that nextflow is installed and that we can find the assembly pipeline:

```bash
# Check that nextflow is installed
nextflow -v
# Check the assembly pipeline can be found at /path/to/pipeline directory <@Nabil please change this as well>
ls /opt/ghru-assembly
```

Nextflow should be preconfigured for you, but if you want to try this on another platform you will need too install `nextflow` and assembly pipeline. You can install them by following the instructions in the [install nextflow](#install-nextflow) or [install pipeline](#install-pipeline) bonus sections.

## Implementation

First we need to create a directory to store the assemblies. We will call this directory `results`. You can create this directory with the following command, replace `user` with your username:

```bash
# Create the results directory
mkdir /workshop/user/results
```

Next, let's create a directory to store the implementation scripts and the working directory. We will call this directory `scripts`. You can create this directory with the following command, replace `user` with your username:

```bash
# Create the scripts directory
mkdir /workshop/user/scripts
```

Now we create a script to run the assembly pipeline. You can create a file called `assembly.sh` in the `scripts` directory using a text editor such as `nano` or `vim`. You can copy and paste the following code into the file and save it:

Please change the output directory in line with your username. 

```bash
#!/bin/bash
NEXTFLOW_WORKFLOWS_DIR='/opt/ghru-assembly'
INPUT_DIR='/data'
OUTPUT_DIR='/workshop/user/results'

nextflow run ${NEXTFLOW_WORKFLOWS_DIR}/main.nf 
    --adapter_file adapters.fas \
    --qc_conditions qc_conditions_nextera_relaxed_dev.yml \
    --input_dir ${INPUT_DIR} \
    --fastq_pattern '*{R,_}{1,2}.f*q.gz' \
    --output_dir ${OUTPUT_DIR} \
    --depth_cutoff 100 \
    --prescreen_file_size_check 12 \
    --confindr_db_path /opt/confindr_db_2019_11_16 \
    --careful \
    --kmer_min_copy 3 \
    -w ${OUTPUT_DIR}/work \
    -resume
```

Finally, you can run the assembly pipeline by executing the script, replace `user` with your username:

```bash
# Run the assembly pipeline
bash /workshop/user/scripts/assembly.sh
```

## Results

The assembly pipeline will create six directories in the `assemblies` directory, replace `user` with your username. 

```bash
# Check the contents of the /results directory
ls /workshop/user/results
```

You will find the fasta-formatted assemblies in the `assemblies` directory. There, you will find `pass`, `warning`, and `failure` directories containing the assemblies according to their quality. You can check the contents of the `assemblies` directory, replace `user` with your username:

```bash
# Check the contents of the /results/assemblies directory 
ls /workshop/user/results
```

Additonally you will find the `quality_reports` directory containing the quality control reports for the assemblies. You can check the contents of the `quality_reports` directory, replace `user` with your username:

```bash
# Check the contents of the /results/quality_reports directory
ls /workshop/user/results/quality_reports
```

You may want to import the quality report (`results/quality_reports/qualifyr_report.tsv`) to your local machine so as to explore whether the assemblies are of high quality or not. You can use the `scp` command to do this, replace `user` with your username:

```bash
# Copy the quality report to your local machine
scp user@159.65.95.44:/workshop/user/results/quality_reports/qualifyr_report.tsv /path/to/local/machine
```

You will be prompted for your password. You can use the same command to copy the assemblies to your local machine (hint: `scp -r` helps you move an entire directory). 

# Bonus Materials

## Fetching data {#fetching-data}

You can use tools such as `wget` or `curl` to fetch data from a remote location such as Figshare, ENA or SRA. For example, you can fetch the data from the following Figshare link:

```bash
# Fetch the data from Figshare
wget https://figshare.com/ndownloader/articles/25266367/versions/1 -O /data/fastqs.zip
# Unzip the data
unzip /data/fastqs.zip -d /data
```

## Install nextflow {#install-nextflow}

This may be a bit of work, but you can install nextflow by following the instructions in the following link: https://www.nextflow.io/docs/latest/getstarted.html

## Install assembly pipeline {#install-pipeline}

To install the assembly pipeline, you can clone the repository from the following link:

```bash
# Clone the assembly pipeline
git clone https://gitlab.com/cgps/ghru/pipelines/assembly.git
```

You will also need docker installed.

***The materials provided in this repository are FREE to use.*** ***This work is licensed under a Creative Commons Attribution 4.0 International License. Reuse is encouraged with acknowledgement.***

